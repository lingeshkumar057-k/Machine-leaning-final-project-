# -*- coding: utf-8 -*-
"""Machine leaning final project

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/11ATdi7GGqaXZP10e530mXQy2lnfYSwaS
"""

import pandas as pd
df=pd.read_csv('/content/WA_Fn-UseC_-HR-Employee-Attrition.csv')
df.head()

import numpy as np

"""# **label Encode categorical variable **"""

from collections.abc import Mapping
from sklearn.preprocessing import LabelEncoder
le=LabelEncoder()

df['Attrition']=le.fit_transform(df['Attrition'])
Mapping1=dict(zip(le.classes_,le.transform(le.classes_)))

df['BusinessTravel']=le.fit_transform(df['BusinessTravel'])
Mapping2=dict(zip(le.classes_,le.transform(le.classes_)))

df['Department']=le.fit_transform(df['Department'])
mapping3=dict(zip(le.classes_,le.transform(le.classes_)))

df['EducationField']=le.fit_transform(df['EducationField'])
mapping4=dict(zip(le.classes_,le.transform(le.classes_)))

df['Gender']=le.fit_transform(df['Gender'])
mapping5=dict(zip(le.classes_,le.transform(le.classes_)))

df['JobRole']=le.fit_transform(df['JobRole'])
mapping6=dict(zip(le.classes_,le.transform(le.classes_)))

df['MaritalStatus']=le.fit_transform(df['MaritalStatus'])
mapping7=dict(zip(le.classes_,le.transform(le.classes_)))

df['OverTime'] = le.fit_transform(df['OverTime'])
mapping8=dict(zip(le.classes_,le.transform(le.classes_)))

df['Over18'] = le.fit_transform(df['Over18'])
mapping9=dict(zip(le.classes_,le.transform(le.classes_)))

print(Mapping1)
print(Mapping2)
print(mapping3)
print(mapping4)
print(mapping5)
print(mapping6)
print(mapping7)
print(mapping8)
print(mapping9)
df.head()

df.columns

x=df.drop(['EmployeeNumber','EmployeeCount', 'StandardHours','OverTime'],axis=1)
y=df['Attrition']

# split data for testing
from sklearn.model_selection import train_test_split
x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=42)

# for check the final value
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix,classification_report

"""## **by using Logistic Regression **"""

from sklearn.linear_model import LogisticRegression
model0 = LogisticRegression()

#fitting the model in logistic regression
model0.fit(x_train,y_train)

model0.intercept_

model0.coef_

y_predicted=model0.predict(x_test)
y_predicted

model0.score(x_test,y_test)

import seaborn as sn
import matplotlib.pyplot as plt
plt.figure(figsize=(30,30))
sn.heatmap(x.corr(),annot=True)
plt.show()

"""by using Random Forest classifier algorithm"""

from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestClassifier

rf_pipe = Pipeline([
    ('scaler', StandardScaler()),
    ('rf', RandomForestClassifier(n_estimators=10, random_state=42))
])
rf_pipe.fit(x_train, y_train)

y_pred_rf = rf_pipe.predict(x_test)
y_pred_rf

rf_pipe.score(x_test,y_test)

from sklearn.metrics import confusion_matrix
cm1=confusion_matrix(y_test,y_pred_rf)
cm1

import seaborn as sn
import matplotlib.pyplot as plt
plt.figure(figsize=(10,7))
sn.heatmap(cm1,annot=True)
plt.show()

from sklearn import tree
# Access the RandomForestClassifier from the pipeline
rf_model = rf_pipe.named_steps['rf']
tree.plot_tree(rf_model.estimators_[0])
plt.show()

# Evaluation Metrics
print("Accuracy:", accuracy_score(y_test, y_pred_rf))
print("Precision:", precision_score(y_test, y_pred_rf, average='weighted'))
print("Recall:", recall_score(y_test, y_pred_rf, average='weighted'))
print("F1 Score:", f1_score(y_test, y_pred_rf, average='weighted'))
print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred_rf))

# Classification Report (includes precision, recall, f1, support for each class)
print("\nClassification Report:\n", classification_report(y_test, y_pred_rf))

from sklearn.svm import SVC
svm_pipe = Pipeline([
    ('scaler', StandardScaler()),
    ('svc', SVC(kernel='rbf',C=30,gamma='auto', random_state=42))])

svm_pipe.fit(x_train, y_train)
y_pred_svm = svm_pipe.predict(x_test)

y_pred_svm

svm_pipe.score(x_test,y_test)

cm=confusion_matrix(y_test,y_pred_svm)
cm

import seaborn as sn
import matplotlib.pyplot as plt
plt.figure(figsize=(10,7))
sn.heatmap(cm,annot=True)
plt.show()

# Evaluation Metrics
print("Accuracy:", accuracy_score(y_test, y_pred_svm))
print("Precision:", precision_score(y_test, y_pred_svm, average='weighted'))
print("Recall:", recall_score(y_test, y_pred_svm, average='weighted'))
print("F1 Score:", f1_score(y_test, y_pred_svm, average='weighted'))
print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred_svm))

# Classification Report (includes precision, recall, f1, support for each class)
print("\nClassification Report:\n", classification_report(y_test, y_pred_svm))

"""by using k nearest neighbour algorithm"""

from sklearn.neighbors import KNeighborsClassifier

knn_pipe = Pipeline([
    ('scaler', StandardScaler()),
    ('knn', KNeighborsClassifier(n_neighbors=3))
])

knn_pipe.fit(x_train, y_train)

y_pred_knn = knn_pipe.predict(x_test)
y_pred_knn

knn_pipe.score(x_test,y_test)

from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report
# Access the KNeighborsClassifier from the pipeline
knn_model = knn_pipe.named_steps['knn']
knn_cm=confusion_matrix(y_test,y_pred_knn)
cm_display=ConfusionMatrixDisplay(knn_cm,display_labels=knn_model.classes_)
cm_display.plot()
plt.show()
print(classification_report(y_test,y_pred_knn))

"""by using SVM and cross validation process"""

from sklearn import svm

from sklearn.model_selection import cross_val_score

pipe_cross=Pipeline([ ('scaler', StandardScaler()),
 ('svc', SVC(kernel='rbf',C=30,gamma='auto', random_state=42))])

pipe_cross.fit(x_train,y_train)

y_pred_cross=pipe_cross.predict(x_test)
y_pred_cross

pipe_cross.score(x_test,y_test)

cross_val_score(svm.SVC(kernel='rbf',C=10,gamma='auto'),x_test,y_test,cv=5)

scores = cross_val_score(pipe_cross, x_train, y_train, cv=5)
print("Cross-validation scores:", scores)
print("Mean cross-validation score:", scores.mean())

from google.colab import drive
drive.mount('/content/drive')